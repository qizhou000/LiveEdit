edit_model_name: "minigpt-4-vicuna-7b"
edit_layer: 31
num_steps: 25
lr: 1.e-2
loss_a_lambda: 1.e-4
loss_m_lambda: 1.e-4
weight_decay: 0
mlp_in_module_tmps: 
- llama_model.model.layers.{}.mlp.gate_proj
- llama_model.model.layers.{}.mlp.up_proj
mlp_out_module_tmps: 
- llama_model.model.layers.{}.mlp.down_proj
